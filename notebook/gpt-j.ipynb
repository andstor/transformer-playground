{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monkey-patched cumsum to fallback to CPU, for compatibility on MPS backend; see https://github.com/pytorch/pytorch/issues/89784\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.helpers.cumsum_mps_fix import reassuring_message\n",
    "print(reassuring_message) # avoid \"unused\" import :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#print all layers of model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#print all layers of model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mandstor/gpt-j-6B-smart-contract\u001b[39m\u001b[39m\"\u001b[39m, use_auth_token\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m tokenizer\u001b[39m.\u001b[39mpad_token \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m[PAD]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mandstor/gpt-j-6B-smart-contract\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_auth_token\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:463\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    462\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    464\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    465\u001b[0m     )\n\u001b[1;32m    466\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    467\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m )\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:2379\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2370\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2372\u001b[0m     (\n\u001b[1;32m   2373\u001b[0m         model,\n\u001b[1;32m   2374\u001b[0m         missing_keys,\n\u001b[1;32m   2375\u001b[0m         unexpected_keys,\n\u001b[1;32m   2376\u001b[0m         mismatched_keys,\n\u001b[1;32m   2377\u001b[0m         offload_index,\n\u001b[1;32m   2378\u001b[0m         error_msgs,\n\u001b[0;32m-> 2379\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   2380\u001b[0m         model,\n\u001b[1;32m   2381\u001b[0m         state_dict,\n\u001b[1;32m   2382\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2383\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2384\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2385\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   2386\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   2387\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   2388\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   2389\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   2390\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   2391\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   2392\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   2393\u001b[0m         load_in_8bit\u001b[39m=\u001b[39;49mload_in_8bit,\n\u001b[1;32m   2394\u001b[0m     )\n\u001b[1;32m   2396\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n\u001b[1;32m   2398\u001b[0m \u001b[39m# make sure token embedding weights are still tied if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:2632\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, load_in_8bit)\u001b[0m\n\u001b[1;32m   2630\u001b[0m \u001b[39mif\u001b[39;00m shard_file \u001b[39min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   2631\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 2632\u001b[0m state_dict \u001b[39m=\u001b[39m load_state_dict(shard_file)\n\u001b[1;32m   2634\u001b[0m \u001b[39m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   2635\u001b[0m \u001b[39m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   2636\u001b[0m mismatched_keys \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   2637\u001b[0m     state_dict,\n\u001b[1;32m   2638\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2642\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   2643\u001b[0m )\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:399\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_load_file(checkpoint_file)\n\u001b[1;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    400\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    401\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/torch/serialization.py:811\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    810\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 811\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    812\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    813\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/torch/serialization.py:1174\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1172\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1173\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1174\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1176\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1178\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/torch/serialization.py:1144\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1143\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1144\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1146\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/Code/playground/transformer/.venv/lib/python3.9/site-packages/torch/serialization.py:1114\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1112\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1114\u001b[0m     storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39;49mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39;49mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1115\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m     typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m   1118\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1119\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1120\u001b[0m         _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"andstor/gpt-j-6B-smart-contract\", use_auth_token=True)\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\"andstor/gpt-j-6B-smart-contract\", use_auth_token=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contract bank {\n",
      "    address owner;\n",
      "    uint balance;\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncontract bank { \\n function deposit() public  payable Own Own Own Own Own Own Own Own Own\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"contract bank {\n",
    "    address owner;\n",
    "    uint balance;\"\"\"\n",
    "\n",
    "ids = tokenizer(prompt, padding=True, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen_tokens = model.generate(\n",
    "            ids,\n",
    "#            attention_mask=ids.ne(tokenizer.pad_token_id).long(),\n",
    "            pad_token_id=50256,\n",
    "            do_sample=True,\n",
    "            max_length=20,\n",
    "            #temperature=0.9,\n",
    "            #use_cache=False\n",
    "        )\n",
    "\n",
    "gen_text = tokenizer.decode(gen_tokens[0], skip_special_tokens=False)\n",
    "print(gen_text)\n",
    "\n",
    "\"\"\"\n",
    "contract bank { \n",
    " function deposit() public  payable Own Own Own Own Own Own Own Own Own\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "   background-color: transparent !important;\n",
       "}\n",
       ".jp-OutputArea-output {\n",
       "   background-color: transparent;\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "   background-color: transparent !important;\n",
    "}\n",
    ".jp-OutputArea-output {\n",
    "   background-color: transparent;\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9c669b91b9a9d35b93c47313685f41364c574a61bffed8af718d56722f40d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
